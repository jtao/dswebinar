{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n9jDdfFs5byP"
      },
      "source": [
        "# Machine Learning with scikit-learn\n",
        "[Jian Tao](https://coehpc.engr.tamu.edu/people/jian-tao/), Texas A&M University\n",
        "\n",
        "Oct 24, 2019"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XcbKAX4X5byQ"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.linear_model import LinearRegression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I5Z5YXFt5byR"
      },
      "source": [
        "## Linear Regression\n",
        "Linear Regression is a statistical technique for estimating the relationships among variables and predicting a continuous-valued attribute associated with an object.\n",
        "Linear Regression fits a linear model with coefficients  to minimize the residual sum of squares between the observed targets in the dataset, and the targets predicted by the linear approximation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "IgfRVL4G5byR"
      },
      "outputs": [],
      "source": [
        "# generate a data set\n",
        "n_samples = 20\n",
        "x = np.linspace(-1.5, 2.0, n_samples)[:, np.newaxis]\n",
        "y = 3 * x + 2 + 0.5*np.random.randn(n_samples, 1)\n",
        "plt.scatter(x, y);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5fKvJ-3B5byS"
      },
      "outputs": [],
      "source": [
        "x.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0nVEJssz5byS"
      },
      "outputs": [],
      "source": [
        "y.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ukP2_Srb5byS"
      },
      "outputs": [],
      "source": [
        "model = LinearRegression()\n",
        "# Fit linear model.\n",
        "model.fit(x, y);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BAu169ep5byS"
      },
      "outputs": [],
      "source": [
        "# Estimated coefficients for the linear regression problem.\n",
        "# If multiple targets are passed during the fit (y 2D),\n",
        "# this is a 2D array of shape (n_targets, n_features), while\n",
        "# if only one target is passed, this is a 1D array of length n_features.\n",
        "model.coef_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wRULw4u55byT"
      },
      "outputs": [],
      "source": [
        "# Independent term in the linear model.\n",
        "model.intercept_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uDNtfjNh5byT"
      },
      "outputs": [],
      "source": [
        "# Returns the coefficient of determination R^2 of the prediction.\n",
        "model.score(x, y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fsbr-bpc5byT"
      },
      "outputs": [],
      "source": [
        "# Plot the data and the model prediction\n",
        "y_fit = model.predict(x)\n",
        "plt.scatter(x, y)\n",
        "plt.plot(x, y_fit);\n",
        "plt.text(-1.5, 6, r\"Y = %f *x + %f\"%(model.coef_, model.intercept_), fontsize=15);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JgDy5NSU5byU"
      },
      "outputs": [],
      "source": [
        "# let's try polynomial fitting with the linear regression\n",
        "x = np.linspace(-1.5, 2.0, n_samples)[:, np.newaxis]\n",
        "y = 3 * x**4 + 2.5*x**2 + 4.7 * x + np.random.randn(n_samples, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mA_K5fp_5byU"
      },
      "outputs": [],
      "source": [
        "x_poly = np.hstack([x, x**2, x**3, x**4])\n",
        "model.fit(x_poly, y);\n",
        "print(model.coef_)\n",
        "y_pred = model.predict(x_poly)\n",
        "plt.scatter(x, y);\n",
        "plt.plot(x, y_pred, 'r');"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HBMGW7cV5byU"
      },
      "outputs": [],
      "source": [
        "x_poly.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KHDGjois5byV"
      },
      "outputs": [],
      "source": [
        "help(np.hstack)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ldiVggPb5byV"
      },
      "source": [
        "## Classification\n",
        "Classification is to Identify to which category an object belongs to based on a training set of data containing observations (or instances) whose category membership is known.\n",
        "\n",
        "Another way to think of classification is as a discrete form of supervised learning where one has a limited number of categories and for each of the n samples provided, one is to try to label them with the correct category or class."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bbfTil9k5byV"
      },
      "source": [
        "#### Classificaiton - SVM\n",
        "Support-vector machines (SVMs), are supervised learning models with associated learning algorithms that analyze data used for classification and regression analysis.\n",
        "\n",
        "The primary task of an SVM algorithm is to find the vector/hyperplane that separates binary sets with the maximum margin to both classes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GtZ_PgyI5byV"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import make_blobs\n",
        "n_samples = 500\n",
        "x, y = make_blobs(n_samples=n_samples, centers=2,\n",
        "                  random_state=0, cluster_std=0.60)\n",
        "plt.scatter(x[:, 0], x[:, 1], c=y, s=50);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IQojWPL75byV"
      },
      "outputs": [],
      "source": [
        "from sklearn.svm import SVC\n",
        "clf = SVC(kernel='linear')\n",
        "clf.fit(x, y);\n",
        "w=clf.coef_[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rr_6lTJZ5byV"
      },
      "outputs": [],
      "source": [
        "plt.scatter(x[:, 0], x[:, 1], c=y, s=50);\n",
        "a = -w[0] / w[1]\n",
        "b = (clf.intercept_[0]) / w[1]\n",
        "x_fit  = np.linspace(-1, 4)\n",
        "plt.plot(x_fit, a * x_fit - b)\n",
        "plt.text(-1, -1, r\"Y = %f *x + %f\"%(a, b), fontsize=15);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3kFBLlJR5byV"
      },
      "source": [
        "#### Classificaiton - KNN Classifier\n",
        "The K-Nearest Neighbors (KNN) algorithm is a method used for algorithm used for classification or for regression. In both cases, the input consists of the k closest training examples in the feature space. Given a new, unknown observation, look up which points have the closest features and assign the predominant class."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KKT48xP85byV"
      },
      "outputs": [],
      "source": [
        "from sklearn import neighbors\n",
        "x, y = make_blobs(n_samples=n_samples, centers=4,\n",
        "                  random_state=0, cluster_std=0.60)\n",
        "plt.scatter(x[:, 0], x[:, 1], c=y, s=50);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aBzcYaQw5byW"
      },
      "outputs": [],
      "source": [
        "# create the model\n",
        "knn = neighbors.KNeighborsClassifier(n_neighbors=4, weights='uniform')\n",
        "\n",
        "# fit the model with the blobs generated above.\n",
        "knn.fit(x, y);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ly157FM_5byW"
      },
      "outputs": [],
      "source": [
        "x_pred = [0, 2]\n",
        "r = knn.predict([x_pred,])\n",
        "plt.scatter(x[:, 0], x[:, 1], c=(y==r[0]));\n",
        "#plt.scatter(x[:, 0], x[:, 1], c=y);\n",
        "plt.scatter(x_pred[0], x_pred[1], c='red', s=50);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G-5y0u8w5byW"
      },
      "source": [
        "## Clustering\n",
        "Cluster analysis or clustering is the task of grouping a set of objects in such a way that objects in the same group (called a cluster) are more similar (in some sense) to each other than to those in other groups (clusters).\n",
        "\n",
        "Common clustering algorithms include K-means, Density-based spatial clustering of applications with noise (DBSCAN) and mean-shift."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I28v1tm55byW"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import make_blobs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DU2taYRV5byX"
      },
      "outputs": [],
      "source": [
        "# We will use the blobs crated above for clustering examples as well.\n",
        "plt.scatter(x[:, 0], x[:, 1], c=y);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RMdWsnVm5byX"
      },
      "source": [
        "#### Clustering - K-Means\n",
        "The K-Means algorithm searches for a predetermined number of clusters within an unlabeled multidimensional dataset.\n",
        "The \"cluster center\" is the arithmetic mean of all the points belonging to the cluster.\n",
        "Each point is closer to its own cluster center than to other cluster centers. K-Means clustering highly depends on the K clusters that is specified at the beginning. It works best when the number of clusters is known.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "leCkFa5h5byX"
      },
      "outputs": [],
      "source": [
        "from sklearn.cluster import KMeans\n",
        "x, y = make_blobs(n_samples=n_samples, centers=4,\n",
        "                  random_state=0, cluster_std=1.5)\n",
        "y_pred = KMeans(n_clusters=4).fit(x)\n",
        "y_pred.cluster_centers_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WcnNQDZ45byX"
      },
      "outputs": [],
      "source": [
        "# original classification\n",
        "plt.scatter(x[:, 0], x[:, 1], c=y);\n",
        "#plt.scatter(y_pred.cluster_centers_[:, 0], y_pred.cluster_centers_[:, 1], c='r', s=80);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N6-ICGgX5byX"
      },
      "outputs": [],
      "source": [
        "# predicted clustering\n",
        "plt.scatter(x[:, 0], x[:, 1], c=y_pred.predict(x));\n",
        "plt.scatter(y_pred.cluster_centers_[:, 0], y_pred.cluster_centers_[:, 1], c='r', s=80);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qXhBJFc35byX"
      },
      "source": [
        "#### Cluster - PCA\n",
        "Principal component analysis (PCA) is a statistical procedure that converts a set of observations of possibly correlated variables into a set of values of linearly uncorrelated variables called principal components. PCA is mostly used as a tool in exploratory data analysis and for making predictive models.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yq3UFWcp5byX"
      },
      "outputs": [],
      "source": [
        "from sklearn import datasets\n",
        "from sklearn.decomposition import PCA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nPew8nWR5byX"
      },
      "outputs": [],
      "source": [
        "iris = datasets.load_iris()\n",
        "n_samples, n_features = iris.data.shape\n",
        "print(iris.keys())\n",
        "print((n_samples, n_features))\n",
        "print(iris.data.shape)\n",
        "print(iris.target.shape)\n",
        "print(iris.target_names)\n",
        "print(iris.feature_names)\n",
        "x, y = iris.data, iris.target"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sx_rRX5_5byX"
      },
      "outputs": [],
      "source": [
        "pca = PCA(n_components=2)\n",
        "x_pca = pca.fit_transform(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6kgvN2FR5byY"
      },
      "outputs": [],
      "source": [
        "print(\"Reduced dataset shape:\", x_pca.shape)\n",
        "plt.scatter(x_pca[:, 0], x_pca[:, 1], c=iris.target, cmap=plt.cm.get_cmap('RdYlBu', 3));\n",
        "formatter = plt.FuncFormatter(lambda i, *args: iris.target_names[int(i)])\n",
        "\n",
        "plt.colorbar(ticks=[0, 1, 2], format=formatter)\n",
        "\n",
        "print(\"Meaning of the 2 components:\")\n",
        "for component in pca.components_:\n",
        "    print(\" + \".join(\"%.3f x %s\" % (value, name)\n",
        "                     for value, name in zip(component,\n",
        "                                            iris.feature_names)))\n",
        "for length, vector in zip(pca.explained_variance_ratio_, pca.components_):\n",
        "    v = vector * 10 * np.sqrt(length)\n",
        "    plt.plot([0, v[0]], [0, v[1]], '-k', lw=3)\n",
        "plt.axis('equal');"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7giaXPN15byY"
      },
      "outputs": [],
      "source": [
        "# variance ratio of the components\n",
        "pca.explained_variance_ratio_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "43MxYDw_5byY"
      },
      "outputs": [],
      "source": [
        "x.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ptyvkFPr5byY"
      },
      "outputs": [],
      "source": [
        "x_pca.shape"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}