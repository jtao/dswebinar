{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/jtao/dswebinar/blob/master/nlp/NLP_with_NLTK.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AMYbTJGjtMoz"
   },
   "source": [
    "# Natural Language Processing with NLTK\n",
    "\n",
    "[Jian Tao](https://coehpc.engr.tamu.edu/people/jian-tao/), Texas A&M University\n",
    "\n",
    "June 30, 2023\n",
    "\n",
    "Converted from \n",
    "\n",
    "**Intro to natural language processing with Python**\n",
    "\n",
    "Notebook by [Juan Cruz Martinez](https://livecodestream.dev/authors/bajcmartinez/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OfKt9ernTGcK"
   },
   "source": [
    "## Setting up the Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aS5aFgDKqOBI"
   },
   "outputs": [],
   "source": [
    "# this is to detect if we are running on Google Colab.\n",
    "import sys\n",
    "IN_COLAB = 'google.colab' in sys.modules\n",
    "import nltk\n",
    "if IN_COLAB:\n",
    "  nltk.download('punkt')    \n",
    "  nltk.download('stopwords')\n",
    "  nltk.download('wordnet')\n",
    "  nltk.download('omw-1.4')\n",
    "  nltk.download('averaged_perceptron_tagger')\n",
    "  nltk.download('maxent_ne_chunker')\n",
    "  nltk.download('words')\n",
    "else:\n",
    "  nltk.data.path.append(\"./nltk_data\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_4JpHHRXTKrI"
   },
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kZAtuBOHr0Hi",
    "outputId": "323b63d4-4ade-44b0-e5f4-3483233b3595"
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "Text = \"Good morning, How you doing? Are you coming tonight?\"\n",
    "Tokenized = word_tokenize(Text)\n",
    "print(Tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YZavEyf3shdA",
    "outputId": "b55c9f59-7aba-40fe-ab08-80fd43e3cece"
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "Text = \"Good morning, How you doing? Are you coming tonight?\"\n",
    "Tokenized = sent_tokenize(Text)\n",
    "print(Tokenized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ug23r1ziTRBB"
   },
   "source": [
    "## Stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NkFPhwmAt0_m",
    "outputId": "745a1d82-a508-428f-e7e6-2a30a265a0ea"
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stopwords = stopwords.words(\"english\")\n",
    "Text = [\"Good\", \"morning\", \"How\", \"you\", \"doing\", \"Are\", \"you\", \"coming\", \"tonight\"]\n",
    "for i in Text:\n",
    "   if i not in stopwords:\n",
    "       print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 174
    },
    "id": "UbC3CKm-vTHs",
    "outputId": "0c92cc1d-aff7-464f-c5a7-d897028c6922"
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stopwords = stopwords.words(\"english\")\n",
    "','.join(stopwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KPDmzpqRTUdn"
   },
   "source": [
    "## Stemming Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JI2Olf5asdTY",
    "outputId": "be2c2f62-48bb-4dc4-84a6-56a7a404b65d"
   },
   "outputs": [],
   "source": [
    "help(nltk.stem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "st2JbM81u0RJ",
    "outputId": "c24312c0-2c10-49bf-e6e0-9bcbb714f3a1"
   },
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "ps = PorterStemmer()\n",
    "words = [\"Loving\", \"Chocolate\", \"Retrieving\"]\n",
    "for i in words:\n",
    "   print(ps.stem(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kBjGg2nrTYAm"
   },
   "source": [
    "## Counting Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1WchynDMVnu8",
    "outputId": "22252980-7b2c-4566-fb96-2bf9c84b1aaa"
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "words = [\"men\", \"teacher\", \"men\", \"woman\"]\n",
    "FreqDist = nltk.FreqDist(words)\n",
    "for i,j in FreqDist.items():\n",
    "   print(i, \"---\", j)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J6au6fb1Tilk"
   },
   "source": [
    "## Word groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7eWR25NzQDtv",
    "outputId": "98bd4194-e70e-45d9-e763-2f574de6d83a"
   },
   "outputs": [],
   "source": [
    "words = \"Learning python was such an amazing experience for me\"\n",
    "word_tokenize = nltk.word_tokenize(words)\n",
    "print(list(nltk.bigrams(word_tokenize)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GzrbKs2jRFfP",
    "outputId": "6a8b2e30-1a89-4927-9bf8-0d3ae372c3a4"
   },
   "outputs": [],
   "source": [
    "word_tokenize = nltk.word_tokenize(words)\n",
    "print(list(nltk.trigrams(word_tokenize)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fj1BCGX_RX_J",
    "outputId": "da827ba7-c571-4745-df19-805d7e05f91b"
   },
   "outputs": [],
   "source": [
    "word_tokenize = nltk.word_tokenize(words)\n",
    "print(list(nltk.ngrams(word_tokenize, 4)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c7BwByxESK4n"
   },
   "source": [
    "## Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uZiPb5cPSRAG",
    "outputId": "489df437-edbf-4910-b995-c306801dd73e"
   },
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "Lem = WordNetLemmatizer()\n",
    "print(Lem.lemmatize(\"believes\"))\n",
    "print(Lem.lemmatize(\"retrieved\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Lgt9YaYISxMv",
    "outputId": "d6f3c921-dbdf-4877-9ec2-8dfaa7c0abd6"
   },
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "Lem = WordNetLemmatizer()\n",
    "print(Lem.lemmatize(\"believes\", pos=\"v\"))\n",
    "print(Lem.lemmatize(\"retrieved\", pos=\"v\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Nd30v8wvS8cM"
   },
   "source": [
    "## POS Taggers\n",
    "Exampls\n",
    "* PRP\tpersonal pronoun (hers, herself, him, himself)\n",
    "* RB\tadverb (occasionally, swiftly)\n",
    "* VBP\tverb, present tense not 3rd person singular(wrap)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "K_Z59DxgTCaD",
    "outputId": "75d8ce09-5023-434a-963e-595fcc4c164e"
   },
   "outputs": [],
   "source": [
    "\n",
    "words = \"we work here\"\n",
    "word_tokenize = nltk.word_tokenize(words)\n",
    "print(nltk.pos_tag(word_tokenize))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9vGnMzBTVAn6"
   },
   "source": [
    "## Named Entity Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X1NpKVSHWSfj",
    "outputId": "3ba4cfd9-05de-4c73-e738-448d4ca911c4"
   },
   "outputs": [],
   "source": [
    "Text = \"tom is in london\"\n",
    "Tokenize = nltk.word_tokenize(Text)\n",
    "POS_tags = nltk.pos_tag(Tokenize)\n",
    "NameEn = nltk.ne_chunk(POS_tags)\n",
    "print(NameEn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "G5DGtIvNYffo",
    "outputId": "154ce810-37dd-41bd-ea46-fc14a081c6fe"
   },
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "Joe_Biden_Tweet = \"today is sunny\"\n",
    "Joe_Biden = TextBlob(Joe_Biden_Tweet)\n",
    "print(Joe_Biden.sentiment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AG2gqbhMZqP8"
   },
   "source": [
    "## Spelling Correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "T9QWtSAyZqvO",
    "outputId": "bf0c73c5-2fce-417c-ae74-d313324cba9c"
   },
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "Text = \"Smalle businesses neede relief\"\n",
    "spelling_mistakes = TextBlob(Text)\n",
    "print(spelling_mistakes.correct())"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "NLP_with_NLTK.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
